# DL-Final-Project

In this project, we propose a deep learning pipeline for generating music based on emotional states of indivisuals. The pipeline consists of an Emotion Classification network based on EfficientNet, and a Music Generation model based on MIDINet. 


The emotion classification network identifies emotions from human facial images. The Music generation model then uses the classification label to generate piano roll melodies. We achieve an accuracy of 80.36\% on the Emotion Classifier for classifying to three emotions (happy, sad, or angry). Our Music Generator produces piano rolls that appear like traditional ones. However, our resulting melodies lack harmony and failed to evoke the intended emotional responses.
